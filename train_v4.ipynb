{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_pipeline_v4 import DataGen\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the dataset from our generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fixup_shape(x, y):\n",
    "  x.set_shape([None, 259, 128]) # n, h, w, c\n",
    "  y.set_shape([None]) # n, nb_classes\n",
    "  return x, y\n",
    "\n",
    "batch_size = 64\n",
    "tracks = pd.read_csv('./data/processed_genres_mel.csv')\n",
    "\n",
    "# Set up train/test split\n",
    "all_idxs = list(range(len(tracks)))\n",
    "np.random.shuffle(all_idxs)\n",
    "num_train = np.floor(len(all_idxs) * 0.8).astype(np.int32)\n",
    "train_idxs = all_idxs[:num_train]\n",
    "test_idxs = all_idxs[num_train:]\n",
    "\n",
    "# Parse filepaths\n",
    "track_fpaths = list(tracks['fpath'])\n",
    "track_fpaths = ['./data/fma_medium' + fpath for fpath in track_fpaths]\n",
    "\n",
    "# Set up generator processing function\n",
    "gen = DataGen()\n",
    "\n",
    "# Set up train data\n",
    "train_data = ([track_fpaths[i] for i in train_idxs],\n",
    "              list(tracks['parent_genre_id'][train_idxs]))\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_data)\n",
    "train_dataset = train_dataset.map(lambda fpath, label: tuple(tf.py_function(gen.get_sample, [fpath, label], [tf.float32, tf.int32])),\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_idxs)).batch(batch_size).map(_fixup_shape)\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Set up test data\n",
    "test_data = ([track_fpaths[i] for i in test_idxs],\n",
    "             list(tracks['parent_genre_id'][test_idxs]))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_data)\n",
    "test_dataset = test_dataset.map(lambda fpath, label: tuple(tf.py_function(gen.get_sample, [fpath, label], [tf.float32, tf.int32])),\n",
    "                                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.shuffle(buffer_size=len(test_idxs)).batch(batch_size).map(_fixup_shape)\n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the class weights for balancing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7109482 ,  1.31339587,  0.21964009,  1.0261446 ,  0.69322986,\n",
       "        4.05647786,  0.24701673,  1.54993781, 10.1148539 , 21.04983108,\n",
       "       13.20074153,  8.75105337,  2.5328252 ,  3.20511831,  1.15555453,\n",
       "       74.17559524])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres = np.array(tracks['parent_genre_id'])\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                  classes=np.unique(genres),\n",
    "                                                  y=genres)\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_4 (Bidirectio  (None, 518)              803936    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 518)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 256)               132864    \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 980,560\n",
      "Trainable params: 980,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      " 76/623 [==>...........................] - ETA: 19:10 - loss: 2.2912 - acc: 0.2726"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(259, dropout=0.2, recurrent_dropout=0.2), input_shape=(259, 128)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),  \n",
    "    tf.keras.layers.Dense(16)\n",
    "])\n",
    "    \n",
    "model.summary()\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[\"acc\"], optimizer='adam')\n",
    "\n",
    "history = model.fit(x=train_dataset, epochs=50,\n",
    "                    validation_data=test_dataset, class_weight=class_weights,\n",
    "                    steps_per_epoch=len(train_idxs) // batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
