{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from soundfile import read as sf_read\n",
    "from librosa import load as lib_load\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv('./data/processed_genres.csv')\n",
    "tracks = np.array(tracks.loc[:, ['parent_genre_id', 'fpath']])\n",
    "\n",
    "dim = 44100 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-0.86430365, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8365129, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0003111732, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Pure tensorflow test\n",
    "for x in range(5000):\n",
    "    fpath = './data/fma_medium' + tracks[x][-1]\n",
    "    audio = tfio.audio.AudioIOTensor(fpath)\n",
    "    shape = tf.cast(audio.shape, tf.dtypes.int32)\n",
    "    #start_idx = tf.random.uniform(shape=[], minval=0, maxval=shape[0] - dim, dtype=tf.dtypes.int32, seed=1)\n",
    "    start_idx = 0\n",
    "    audio_slice = audio[start_idx:start_idx + dim]\n",
    "    # Convert to one channel\n",
    "    # either by averaging stereo channels or removing extra dim on mono\n",
    "    if tf.equal(shape[-1], 2):\n",
    "        audio_tensor = tf.reduce_mean(audio_slice, axis=[-1])\n",
    "    else:\n",
    "        audio_tensor = tf.squeeze(audio_slice, axis=[-1])\n",
    "\n",
    "    print(tf.reduce_min(audio_tensor))\n",
    "    print(tf.reduce_max(audio_tensor))\n",
    "    print(tf.reduce_mean(audio_tensor))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-0.86430377, shape=(), dtype=float32)\n",
      "tf.Tensor(0.83651304, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002738177, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Librosa test\n",
    "for x in range(5000):\n",
    "    fpath = './data/fma_medium' + tracks[x][-1]\n",
    "    audio = tfio.audio.AudioIOTensor(fpath)\n",
    "    shape = tf.cast(audio.shape, tf.dtypes.int32)\n",
    "    #start_idx = tf.random.uniform(shape=[], minval=0, maxval=tf.cast(tf.divide(shape[0] - dim, 44100), tf.dtypes.float32), dtype=tf.dtypes.float32)\n",
    "    start_idx = 0\n",
    "    audio_tensor, _ = lib_load(fpath, sr=44100, mono=True, offset=start_idx, duration=3.0)\n",
    "\n",
    "    print(tf.reduce_min(audio_tensor))\n",
    "    print(tf.reduce_max(audio_tensor))\n",
    "    print(tf.reduce_mean(audio_tensor))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-0.8643037676811218, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8365130126476288, shape=(), dtype=float64)\n",
      "tf.Tensor(0.00027381753228947474, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Soundfile test\n",
    "for x in range(5000):\n",
    "    fpath = './data/fma_medium' + tracks[x][-1]\n",
    "    audio = tfio.audio.AudioIOTensor(fpath)\n",
    "    shape = tf.cast(audio.shape, tf.dtypes.int32)\n",
    "    #start_idx = tf.random.uniform(shape=[], minval=0, maxval=shape[0] - dim, dtype=tf.dtypes.int32, seed=1)\n",
    "    start_idx = 0\n",
    "    audio_slice, _ = sf_read(fpath, frames=dim, start=start_idx)\n",
    "    # Convert to one channel by averaging stereo channels\n",
    "    if tf.equal(shape[-1], 2):\n",
    "        audio_tensor = tf.reduce_mean(audio_slice, axis=[-1])\n",
    "    \n",
    "    print(tf.reduce_min(audio_tensor))\n",
    "    print(tf.reduce_max(audio_tensor))\n",
    "    print(tf.reduce_mean(audio_tensor))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
